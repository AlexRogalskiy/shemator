<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
  
  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,400italic,400,600' rel='stylesheet' type='text/css'>
  <!-- Use title if it's in the page YAML frontmatter -->
  <title>
      Accessing Hadoop with PXF |
    Pivotal Greenplum Docs
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="/stylesheets/all.css" rel="stylesheet" media="screen, print" />
  <link href="/stylesheets/print.css" rel="stylesheet" media="print" />
  <link href='/images/favicon.ico' rel='shortcut icon'>

  <script src="/javascripts/all.js"></script>
  

<!-- Google Tag Manager -->
<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-MW4LZHR');
</script>


<!-- <script type="text/javascript">
  if (window.location.host === 'gpdb.docs.pivotal.io') {
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39702075-1']);
    _gaq.push(['_setDomainName', 'pivotal.io']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script');
      ga.type = 'text/javascript';
      ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(ga, s);
    })();
  }
</script> -->

<script type="text/javascript">
  var blackList = ['acceptance'];

  blackList.forEach(function(blackListedEnv) {
    if (document.URL.indexOf(blackListedEnv) > -1 && blackListedEnv != "") {
      $('head').append('<meta name="hashtag" content="PivotalMoment">');
    }
  });
</script>

<!-- CrazyEgg Tracking Script -->
<!--   <script type="text/javascript">
  setTimeout(function(){var a=document.createElement("script");
  var b=document.getElementsByTagName("script")[0];
  a.src=document.location.protocol+"//script.crazyegg.com/pages/scripts/0055/2990.js?"+Math.floor(new Date().getTime()/3600000);
  a.async=true;a.type="text/javascript";b.parentNode.insertBefore(a,b)}, 1);
  </script> -->

<!-- Munchkin Marketo Script -->
<!-- <script type="text/javascript">
  (function() {
    var didInit = false;

    function initMunchkin() {
      if (didInit === false) {
        didInit = true;
        Munchkin.init('625-IUJ-009');
      }
    }

    var s = document.createElement('script');
    s.type = 'text/javascript';
    s.async = true;
    s.src = document.location.protocol + '//munchkin.marketo.net/munchkin.js';
    s.onreadystatechange = function() {
      if (this.readyState == 'complete' || this.readyState == 'loaded') {
        initMunchkin();
      }
    };
    s.onload = initMunchkin;
    document.getElementsByTagName('head')[0].appendChild(s);
  })();
</script> -->

</head>

<body class="x5220 x5220_pxf x5220_pxf_access_hdfs has-subnav">

<div class="viewport">
  <div class='wrap'>
    <script type="text/javascript">
      document.domain = "pivotal.io";
    </script>

      <header class="global-header header header-layout js-bar-links">
    <div class='super-nav'>
      <div class='container-modified'>
        <a href="https://docs.pivotal.io" class="global-header-title">
          <img class="pivotal-logo" src="https://d1fto35gcfffzn.cloudfront.net/images/docs/logo-docs.svg">
        </a>
        <div class='header-links'>
           <div class="header-item">
            <a href="https://tanzu.vmware.com/support">Support</a>
          </div>
          <div class="header-item">
            <a href="https://network.pivotal.io">Downloads</a>
          </div>
          <div class='header-item' id='contact-header-item'>
            <a href='https://tanzu.vmware.com/contact'>Contact Us</a>
          </div>
          <div class='header-item'>
            <a href="https://login.run.pivotal.io">Sign In</a>
          </div>
        </div>
      </div>
    </div>
    <div id='info-search-bar'>
      <div class='container-modified'>
          <div class="local-header title-container">
    <div class="local-header local-title clearfix">
      <div class='img-container'><img src="/images/icon_gpdb.png"></div>
      <span class="local-header-title">Pivotal Greenplum</span>
      <span onClick="return true" class="local-header local-version header-dropdown">
        <a class="local-header header-dropdown-link">v5.22</a>
        <span class="local-header header-dropdown-content">
          <ul>
                <li>
                    <a href="/6latest/pxf/access_hdfs.html">v6.x</a>
                </li>
                <li>
                    <a href="/5280/pxf/access_hdfs.html">v5.28</a>
                </li>
                <li>
                    <a href="/5270/pxf/access_hdfs.html">v5.27</a>
                </li>
                <li>
                    <a href="/5260/pxf/access_hdfs.html">v5.26</a>
                </li>
                <li>
                    <a href="/5250/pxf/access_hdfs.html">v5.25</a>
                </li>
                <li>
                    <a href="/5240/pxf/access_hdfs.html">v5.24</a>
                </li>
                <li>
                    <a href="/5230/pxf/access_hdfs.html">v5.23</a>
                </li>
                <li>
                    <a href="/5220/pxf/access_hdfs.html">v5.22</a>
                </li>
                <li>
                    <a href="/5210/pxf/access_hdfs.html">v5.21</a>
                </li>
                <li>
                    <a href="/5200/pxf/access_hdfs.html">v5.20</a>
                </li>
                <li>
                    <a href="/5190/pxf/access_hdfs.html">v5.19</a>
                </li>
                <li>
                    <a href="/5180/pxf/access_hdfs.html">v5.18</a>
                </li>
                <li>
                    <a href="/5170/pxf/access_hdfs.html">v5.17</a>
                </li>
                <li>
                    <a href="/5160/pxf/access_hdfs.html">v5.16</a>
                </li>
                <li>
                    <a href="/5150/pxf/access_hdfs.html">v5.15</a>
                </li>
                <li>
                    <a href="/5140/pxf/access_hdfs.html">v5.14</a>
                </li>
                <li>
                    <a href="/5130/pxf/access_hdfs.html">v5.13</a>
                </li>
                <li>
                    <a href="/5120/pxf/access_hdfs.html">v5.12</a>
                </li>
                <li>
                    <a href="/5110/pxf/access_hdfs.html">v5.11</a>
                </li>
                <li>
                    <a href="/5100/pxf/access_hdfs.html">v5.10</a>
                </li>
                <li>
                    <a href="/590/pxf/access_hdfs.html">v5.9</a>
                </li>
                <li>
                    <a href="/580/pxf/access_hdfs.html">v5.8</a>
                </li>
                <li>
                    <a href="/570/pxf/access_hdfs.html">v5.7</a>
                </li>
                <li>
                    <a href="/560/pxf/access_hdfs.html">v5.6</a>
                </li>
                <li>
                    <a href="/550/pxf/access_hdfs.html">v5.5</a>
                </li>
                <li>
                    <a href="/540/pxf/access_hdfs.html">v5.4</a>
                </li>
                <li>
                    <a href="/530/pxf/access_hdfs.html">v5.3</a>
                </li>
                <li>
                    <a href="/520/pxf/access_hdfs.html">v5.2</a>
                </li>
                <li>
                    <a href="/510/pxf/access_hdfs.html">v5.1</a>
                </li>
                <li>
                    <a href="/500/pxf/access_hdfs.html">v5.0</a>
                </li>
                <li>
                    <a href="/43latest/pxf/access_hdfs.html">v4.3.x</a>
                </li>
          </ul>
        </span>
      </span>

      <!-- search was here -->
    </div>
  </div>

        <div class="header-item embedded-searchbar">
            <form method="get" action="/search">
              <input name="q" placeholder="Search Greenplum 5.22" class="search-box" />
                <input type="hidden" name="product_name" value="Pivotal Greenplum" />
                <input type="hidden" name="product_version" value="5.22"/>
            </form>
        </div>
        <div class="btn-menu" data-behavior="MenuMobile"></div>
        <div class='header-links mobile-only'>
          <div class="header-item" id='docs-header-item'>
            <a href='https://docs.pivotal.io'>All docs</a>
          </div>
          <div class="header-item">
            <a href="https://network.pivotal.io">Downloads</a>
          </div>
          <div class="header-item">
            <a href="https://tanzu.vmware.com/support">Support</a>
          </div>
          <div class='header-item' id='contact-header-item'>
            <a href='https://tanzu.vmware.com/contact'>Contact Us</a>
          </div>
          <div class='header-item'>
            <a href="https://login.run.pivotal.io">Sign In</a>
          </div>

          <div class="header-item embedded-searchbar">
              <form method="get" action="/search">
                <input name="q" placeholder="Search Greenplum 5.22" class="search-box" />
                  <input type="hidden" name="product_name" value="Pivotal Greenplum" />
                  <input type="hidden" name="product_version" value="5.22"/>
              </form>
          </div>
        </div>
      </div>
    </div>
  </header>



    <div class="container" id='container-main'>
      <div id='container-main-inner'>

        <!--googleoff: index-->
        <div id="sub-nav" class="js-sidenav nav-container" role="navigation">
  <a class="sidenav-title" data-behavior="SubMenuMobile">  Doc Index</a>
  <div class="nav-content">
    <ul>
      <li>
        <a href="/5220/main/index.html">Pivotal Greenplum&reg; 5.22 Documentation</a>
      </li>
      <li>
        <a href="/5220/pxf/overview_pxf.html">Greenplum Platform Extension Framework (PXF)</a>
      <li>
      <li class="has_submenu">
        <a href="/5220/pxf/intro_pxf.html">Introduction to PXF</a>
        <ul>
          <li><a href="/5220/pxf/filter_push.html">About PXF Filter Pushdown</a></li>
          <li><a href="/5220/pxf/col_project.html">About Column Projection in PXF</a></li>
        </ul>
      </li>
      <li class="has_submenu">
        <span>Administering PXF</span>
        <ul>
          <li class="has_submenu">
            <a href="/5220/pxf/instcfg_pxf.html">Configuring PXF</a>
            <ul>
              <li><a href="/5220/pxf/about_pxf_dir.html">About the PXF Installation and Configuration Directories</a></li>
              <li>
                <a href="/5220/pxf/install_java.html">Installing Java for PXF</a>
              </li>
              <li>
                <a href="/5220/pxf/init_pxf.html">Initializing PXF</a>
              </li>
              <li>
                <a href="/5220/pxf/cfg_server.html">About PXF Server Configuration</a>
              </li>
              <li class="has_submenu">
                <a href="/5220/pxf/client_instcfg.html">Configuring Hadoop Connectors (Optional)</a>
                <ul>
                  <li>
                    <a href="/5220/pxf/pxfuserimpers.html">Configuring User Impersonation and Proxying</a>
                  </li>
                  <li>
                    <a href="/5220/pxf/pxf_kerbhdfs.html">Configuring PXF for Secure HDFS</a>
                  </li>
                </ul>
              </li>
              <li>
                <a href="/5220/pxf/objstore_cfg.html">Configuring Connectors to Azure, Google Cloud Storage, Minio, and S3 Object Stores (Optional)</a>
              </li>
              <li>
                <a href="/5220/pxf/jdbc_cfg.html">Configuring the JDBC Connector (Optional)</a>
              </li>
              <li>
                <a href="/5220/pxf/cfghostport.html">Configuring the PXF Agent Host and Port (Optional)</a>
              </li>
            </ul>
          </li>
          <li>
            <a href="/5220/pxf/upgrade_pxf.html">Upgrading PXF</a>
          </li>
          <li>
            <a href="/5220/pxf/cfginitstart_pxf.html">Starting, Stopping, and Restarting PXF</a>
          </li>
          <li>
            <a href="/5220/pxf/using_pxf.html">Granting Users Access to PXF</a>
          </li>
          <li>
            <a href="/5220/pxf/reg_jar_depend.html">Registering PXF JAR Dependencies</a>
          </li>
          <li>
            <a href="/5220/pxf/monitor_pxf.html">Monitoring PXF</a>
          </li>
        </ul>
      </li>
      <li class="has_submenu">
        <a href="/5220/pxf/access_hdfs.html">Accessing Hadoop with PXF</a>
        <ul>
          <li><a href="/5220/pxf/hdfs_text.html">Reading and Writing Text Data</a></li>
          <li><a href="/5220/pxf/hdfs_avro.html">Reading Avro Data</a></li>
          <li><a href="/5220/pxf/hdfs_json.html">Reading JSON Data</a></li>
          <li><a href="/5220/pxf/hdfs_parquet.html">Reading and Writing Parquet Data</a></li>
          <li><a href="/5220/pxf/hdfs_seqfile.html">Reading and Writing SequenceFile Data</a></li>
          <li><a href="/5220/pxf/hdfs_fileasrow.html">Reading a Multi-Line Text File into a Single Table Row</a></li>
          <li><a href="/5220/pxf/hive_pxf.html">Reading Hive Table Data</a></li>
          <li><a href="/5220/pxf/hbase_pxf.html">Reading HBase Table Data</a></li>
        </ul>
      </li>
      <li class="has_submenu">
        <a href="/5220/pxf/access_objstore.html">Accessing Azure, Google Cloud Storage, Minio, and S3 Object Stores with PXF</a>
        <ul>
          <li><a href="/5220/pxf/objstore_text.html">Reading and Writing Text Data</a></li>
          <li><a href="/5220/pxf/objstore_avro.html">Reading Avro Data</a></li>
          <li><a href="/5220/pxf/objstore_json.html">Reading JSON Data</a></li>
          <li><a href="/5220/pxf/objstore_parquet.html">Reading and Writing Parquet Data</a></li>
          <li><a href="/5220/pxf/objstore_seqfile.html">Reading and Writing SequenceFile Data</a></li>
          <li><a href="/5220/pxf/objstore_fileasrow.html">Reading a Multi-Line Text File into a Single Table Row</a></li>
        </ul>
      </li>
      <li>
        <a href="/5220/pxf/jdbc_pxf.html">Accessing an SQL Database with PXF (JDBC)</a>
      </li>
      <li>
        <a href="/5220/pxf/troubleshooting_pxf.html">Troubleshooting PXF</a>
      </li>
      <li class="has_submenu">
        <a href="/5220/pxf/ref/pxf-ref.html">PXF Utility Reference</a>
        <ul>
          <li><a href="/5220/pxf/ref/pxf-cluster.html">pxf cluster</a></li>
          <li><a href="/5220/pxf/ref/pxf.html">pxf</a></li>
        </ul>
      </li>
      <!--li class="has_submenu">
        <a href="/5220/pxf/sdk/dev_overview.html">Using the PXF Java SDK</a>
        <ul>
          <li><a href="/5220/pxf/sdk/dev_concepts.html">PXF Developer Concepts</a></li>
          <li><a href="/5220/pxf/sdk/pxfapi.html">Introducing the PXF API</a></li>
          <li><a href="/5220/pxf/sdk/build_conn.html">Building a Connector</a></li>
          <li class="has_submenu">
            <a href="/5220/pxf/sdk/deploy_conn.html">Deploying a Connector</a>
            <ul>
              <li><a href="/5220/pxf/sdk/deploy_profile.html">Deploying a Profile</a> </li>
            </ul>
          </li>
        </ul>
      </li-->
      <li>
        <a href="/5220/admin_guide/external/pxf-overview.html" format="dita" scope="peer">Back to the Administrator Guide</a>
     </li>
    </ul>
  </div>
</div>
<!--end of sub-nav-->

        <!--googleon: index-->

        <main class="content content-layout" id="js-content" role="main">
          <a id="top"></a>
            <h1 class="title-container" >
    Accessing Hadoop with PXF
  </h1>

            <div id="feedback">
  <p class="note">A newer version of this documentation is available. Use the version menu above to view the most up-to-date release of the Greenplum 5.x documentation.</p>
</div>

            <div id="js-quick-links" >
              <div class="quick-links"><ul>
<li><a href="#hdfs_arch">Architecture</a></li>
<li><a href="#hadoop_prereq">Prerequisites</a></li>
<li><a href="#hdfs_cmdline">HDFS Shell Command Primer</a></li>
<li><a href="#hadoop_connectors">Connectors, Data Formats, and Profiles</a></li>
</ul></div>
            </div>
          <div class="to-top" id="js-to-top">
            <a href="#top" title="back to top"></a>
          </div>
          <!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

<p>PXF is compatible with Cloudera, Hortonworks Data Platform, MapR, and generic Apache Hadoop distributions. PXF is installed with HDFS, Hive, and HBase connectors. You use these connectors to access varied formats of data from these Hadoop distributions.</p>

<h2 id="architecture"><a id="hdfs_arch"></a>Architecture</h2>

<p>HDFS is the primary distributed storage mechanism used by Apache Hadoop. When a user or application performs a query on a PXF external table that references an HDFS file, the Greenplum Database master node dispatches the query to all segment hosts. Each segment instance contacts the PXF agent running on its host. When it receives the request from a segment instance, the PXF agent:</p>

<ol>
<li>Allocates a worker thread to serve the request from a segment.</li>
<li>Invokes the HDFS Java API to request metadata information for the HDFS file from the HDFS NameNode. </li>
<li>Provides the metadata information returned by the HDFS NameNode to the segment instance.<br></li>
</ol>

<p><span class="figtitleprefix">Figure: </span>PXF-to-Hadoop Architecture</p>

<p><img src="graphics/pxfarch.png" class="image" /></p>

<p>A segment instance uses its Greenplum Database <code>gp_segment_id</code> and the file block information described in the metadata to assign itself a specific portion of the query data. The segment instance then sends a request to the PXF agent to read the assigned data. This data may reside on one or more HDFS DataNodes.</p>

<p>The PXF agent invokes the HDFS Java API to read the data and delivers it to the segment instance. The segment instance delivers its portion of the data to the Greenplum Database master node. This communication occurs across segment hosts and segment instances in parallel.</p>

<h2 id="prerequisites"><a id="hadoop_prereq"></a>Prerequisites</h2>

<p>Before working with Hadoop data using PXF, ensure that:</p>

<ul>
<li>You have configured and initialized PXF, and PXF is running on each Greenplum Database segment host. See <a href="/5220/pxf/instcfg_pxf.html">Configuring PXF</a> for additional information.</li>
<li>You have configured the PXF Hadoop Connectors that you plan to use. Refer to <a href="/5220/pxf/client_instcfg.html">Configuring PXF Hadoop Connectors</a> for instructions. If you plan to access JSON-formatted data stored in a Cloudera Hadoop cluster, PXF requires a Cloudera version 5.8 or later Hadoop distribution.</li>
<li>If user impersonation is enabled (the default), ensure that you have granted read (and write as appropriate) permission to the HDFS files and directories that will be accessed as external tables in Greenplum Database to each Greenplum Database user/role name that will access the HDFS files and directories. If user impersonation is not enabled, you must grant this permission to the <code>gpadmin</code> user.</li>
<li>Time is synchronized between the Greenplum Database segment hosts and the external Hadoop systems.</li>
</ul>

<h2 id="hdfs-shell-command-primer"><a id="hdfs_cmdline"></a>HDFS Shell Command Primer</h2>

<p>Examples in the PXF Hadoop topics access files on HDFS. You can choose to access files that already exist in your HDFS cluster. Or, you can follow the steps in the examples to create new files.</p>

<p>A Hadoop installation includes command-line tools that interact directly with your HDFS file system. These tools support typical file system operations that include copying and listing files, changing file permissions, and so forth. You run these tools on a system with a Hadoop client installation. By default, Greenplum Database hosts do not
include a Hadoop client installation.</p>

<p>The HDFS file system command syntax is <code>hdfs dfs &lt;options&gt; [&lt;file&gt;]</code>. Invoked with no options, <code>hdfs dfs</code> lists the file system options supported by the tool.</p>

<p>The user invoking the <code>hdfs dfs</code> command must have read privileges on the HDFS data store to list and view directory and file contents, and write permission to create directories and files.</p>

<p>The <code>hdfs dfs</code> options used in the PXF Hadoop topics are:</p>

<table><thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>-cat</code></td>
<td>Display file contents.</td>
</tr>
<tr>
<td><code>-mkdir</code></td>
<td>Create a directory in HDFS.</td>
</tr>
<tr>
<td><code>-put</code></td>
<td>Copy a file from the local file system to HDFS.</td>
</tr>
</tbody></table>

<p>Examples:</p>

<p>Create a directory in HDFS:</p>
<pre class="highlight shell"><code><span class="gp">$ </span>hdfs dfs -mkdir -p /data/exampledir
</code></pre>

<p>Copy a text file from your local file system to HDFS:</p>
<pre class="highlight shell"><code><span class="gp">$ </span>hdfs dfs -put /tmp/example.txt /data/exampledir/
</code></pre>

<p>Display the contents of a text file located in HDFS:</p>
<pre class="highlight shell"><code><span class="gp">$ </span>hdfs dfs -cat /data/exampledir/example.txt
</code></pre>

<h2 id="connectors,-data-formats,-and-profiles"><a id="hadoop_connectors"></a>Connectors, Data Formats, and Profiles</h2>

<p>The PXF Hadoop connectors provide built-in profiles to support the following data formats:</p>

<ul>
<li>Text</li>
<li>Avro</li>
<li>JSON</li>
<li>ORC</li>
<li>Parquet</li>
<li>RCFile</li>
<li>SequenceFile</li>
<li>AvroSequenceFile</li>
</ul>

<p>The PXF Hadoop connectors expose the following profiles to read, and in many cases write, these supported data formats:</p>

<table><thead>
<tr>
<th>Data Source</th>
<th>Data Format</th>
<th>Profile Name(s)</th>
<th>Deprecated Profile Name</th>
</tr>
</thead><tbody>
<tr>
<td>HDFS</td>
<td>delimited single line <a href="/5220/pxf/hdfs_text.html#profile_text">text</a></td>
<td>hdfs:text</td>
<td>HdfsTextSimple</td>
</tr>
<tr>
<td>HDFS</td>
<td>delimited <a href="/5220/pxf/hdfs_text.html#profile_textmulti">text with quoted linefeeds</a></td>
<td>hdfs:text:multi</td>
<td>HdfsTextMulti</td>
</tr>
<tr>
<td>HDFS</td>
<td><a href="/5220/pxf/hdfs_avro.html">Avro</a></td>
<td>hdfs:avro</td>
<td>Avro</td>
</tr>
<tr>
<td>HDFS</td>
<td><a href="/5220/pxf/hdfs_json.html">JSON</a></td>
<td>hdfs:json</td>
<td>Json</td>
</tr>
<tr>
<td>HDFS</td>
<td><a href="/5220/pxf/hdfs_parquet.html">Parquet</a></td>
<td>hdfs:parquet</td>
<td>Parquet</td>
</tr>
<tr>
<td>HDFS</td>
<td>AvroSequenceFile</td>
<td>hdfs:AvroSequenceFile</td>
<td>n/a</td>
</tr>
<tr>
<td>HDFS</td>
<td><a href="/5220/pxf/hdfs_seqfile.html">SequenceFile</a></td>
<td>hdfs:SequenceFile</td>
<td>SequenceWritable</td>
</tr>
<tr>
<td><a href="/5220/pxf/hive_pxf.html">Hive</a></td>
<td>stored as TextFile</td>
<td>Hive, <a href="/5220/pxf/hive_pxf.html#hive_text">HiveText</a></td>
<td>n/a</td>
</tr>
<tr>
<td><a href="/5220/pxf/hive_pxf.html">Hive</a></td>
<td>stored as SequenceFile</td>
<td>Hive</td>
<td>n/a</td>
</tr>
<tr>
<td><a href="/5220/pxf/hive_pxf.html">Hive</a></td>
<td>stored as RCFile</td>
<td>Hive, <a href="/5220/pxf/hive_pxf.html#hive_hiverc">HiveRC</a></td>
<td>n/a</td>
</tr>
<tr>
<td><a href="/5220/pxf/hive_pxf.html">Hive</a></td>
<td>stored as ORC</td>
<td>Hive, <a href="/5220/pxf/hive_pxf.html#hive_orc">HiveORC</a>, HiveVectorizedORC</td>
<td>n/a</td>
</tr>
<tr>
<td><a href="/5220/pxf/hive_pxf.html">Hive</a></td>
<td>stored as Parquet</td>
<td>Hive</td>
<td>n/a</td>
</tr>
<tr>
<td><a href="/5220/pxf/hbase_pxf.html">HBase</a></td>
<td>Any</td>
<td>HBase</td>
<td>n/a</td>
</tr>
</tbody></table>

<p>You provide the profile name when you specify the <code>pxf</code> protocol on a <code>CREATE EXTERNAL TABLE</code> command to create a Greenplum Database external table that references a Hadoop file, directory, or table. For example, the following command creates an external table that uses the default server and specifies the profile named <code>hdfs:text</code>:</p>
<pre class="highlight sql"><code><span class="k">CREATE</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">pxf_hdfs_text</span><span class="p">(</span><span class="k">location</span> <span class="n">text</span><span class="p">,</span> <span class="k">month</span> <span class="n">text</span><span class="p">,</span> <span class="n">num_orders</span> <span class="n">int</span><span class="p">,</span> <span class="n">total_sales</span> <span class="n">float8</span><span class="p">)</span>
   <span class="k">LOCATION</span> <span class="p">(</span><span class="s1">'pxf://data/pxf_examples/pxf_hdfs_simple.txt?PROFILE=hdfs:text'</span><span class="p">)</span>
<span class="n">FORMAT</span> <span class="s1">'TEXT'</span> <span class="p">(</span><span class="k">delimiter</span><span class="o">=</span><span class="n">E</span><span class="s1">','</span><span class="p">);</span>
</code></pre>

          <div></div>

          <footer class="site-footer-links">
            <div class="copyright">
  <a href='https://www.vmware.com/help/privacy.html'  target="_blank">Privacy Policy</a> | 
  <a href='https://www.vmware.com/help/legal.html'  target="_blank">Terms of Use</a>
  <div id="teconsent"></div>

  <br/>
  Copyright &copy; 2020 <a href='https://vmware.com' target="_blank">VMware</a>, Inc. or its affiliates. All Rights Reserved.
  <br/>
  <br/>
</div>
<div class="support">
  Need help? <a href="https://tanzu.vmware.com/support" target="_blank">Visit Support</a>
</div>


          </footer>
        </main>
        <div class='sidebar'>
            <div id="js-quick-links" >
              <div class="quick-links"><ul>
<li><a href="#hdfs_arch">Architecture</a></li>
<li><a href="#hadoop_prereq">Prerequisites</a></li>
<li><a href="#hdfs_cmdline">HDFS Shell Command Primer</a></li>
<li><a href="#hadoop_connectors">Connectors, Data Formats, and Profiles</a></li>
</ul></div>
            </div>
            <div class='product-info'>
              <a href="/5220/relnotes/gpdb-5220-release-notes.html">Release Notes</a><br/>
                <a href="https://network.pivotal.io/products/pivotal-gpdb/">Download</a><br/>
                <a href="https://community.pivotal.io/s/topic/0TO0P000000IKdLWAW/pivotal-greenplum">Ask for Help</a><br/>
                <a href="https://community.pivotal.io/s/topic/0TO0P000000IKdLWAW/pivotal-greenplum?tabset-fea77=2">Knowledge Base</a><br/>
                <a href="/5220/pdf/GPDB5220Docs.pdf">PDF</a><br/>
            </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div id="scrim"></div>

</body>
</html>
